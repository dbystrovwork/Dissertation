{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Structural Balance & GNN Experiment\n\n**Hypothesis:** MagNet outperforms GCN when graphs are structurally unbalanced.\n\n**Unbalance score:** `1 - rho(A_mag) / rho(A_sym)` where:\n- `A_sym` = symmetric (undirected) adjacency\n- `A_mag` = Hermitian (magnetic) adjacency with phase encoding direction\n\nHigher score = more directional information lost when symmetrizing = more potential for MagNet advantage."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup & Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom scipy.linalg import eigvalsh\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Matrix Construction\n\ndef build_matrices(edge_index, num_nodes, q=0.1):\n    \"\"\"\n    Build normalized adjacency matrices for GCN and MagNet.\n    \n    Args:\n        edge_index: [2, E] tensor of directed edges\n        num_nodes: number of nodes\n        q: phase parameter (0.1 gives good real/imag balance)\n    \n    Returns:\n        A_gcn: symmetric normalized adjacency\n        A_mag: Hermitian normalized adjacency\n    \"\"\"\n    # Symmetric adjacency (treat all edges as undirected)\n    A_sym = torch.zeros(num_nodes, num_nodes)\n    for i in range(edge_index.shape[1]):\n        u, v = edge_index[0, i].item(), edge_index[1, i].item()\n        A_sym[u, v] = 1.0\n        A_sym[v, u] = 1.0\n    \n    # Add self-loops\n    A_sym = A_sym + torch.eye(num_nodes)\n    \n    # Degree normalization\n    D = A_sym.sum(dim=1)\n    D_inv_sqrt = torch.zeros(num_nodes)\n    D_inv_sqrt[D > 0] = 1.0 / torch.sqrt(D[D > 0])\n    D_mat = torch.diag(D_inv_sqrt)\n    \n    # GCN: symmetric normalized\n    A_gcn = D_mat @ A_sym @ D_mat\n    \n    # MagNet: Hermitian with phase encoding direction\n    A_mag = torch.eye(num_nodes, dtype=torch.complex64)  # Self-loops\n    phase = 2 * np.pi * q\n    for i in range(edge_index.shape[1]):\n        u, v = edge_index[0, i].item(), edge_index[1, i].item()\n        A_mag[u, v] = np.exp(1j * phase)   # u -> v\n        A_mag[v, u] = np.exp(-1j * phase)  # Hermitian conjugate\n    \n    # Same normalization\n    D_mat_c = D_mat.to(torch.complex64)\n    A_mag = D_mat_c @ A_mag @ D_mat_c\n    \n    return A_gcn, A_mag\n\n\ndef unbalance_score(edge_index, num_nodes, q=0.1):\n    \"\"\"Compute structural unbalance: 1 - rho(A_mag)/rho(A_sym).\"\"\"\n    A_gcn, A_mag = build_matrices(edge_index, num_nodes, q)\n    \n    rho_gcn = np.max(np.abs(np.linalg.eigvalsh(A_gcn.numpy())))\n    rho_mag = np.max(np.abs(np.linalg.eigvals(A_mag.numpy())))\n    \n    if rho_gcn == 0:\n        return 0.0\n    return 1 - rho_mag / rho_gcn\n\n\n# Test\nprint(\"Testing matrix construction...\")\ntest_edges = torch.tensor([[0,1,2],[1,2,0]], dtype=torch.long)\nA_g, A_m = build_matrices(test_edges, 3, q=0.1)\nprint(f\"GCN matrix shape: {A_g.shape}\")\nprint(f\"MagNet matrix shape: {A_m.shape}\")\nprint(f\"Unbalance score: {unbalance_score(test_edges, 3):.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Graph Generation\n\ndef generate_sbm(n, k, p_in, p_out, balanced=True):\n    \"\"\"\n    Generate directed stochastic block model.\n    \n    balanced=True: consistent edge directions (structurally balanced)\n    balanced=False: random directions (creates odd cycles, unbalanced)\n    \"\"\"\n    labels = torch.tensor([i % k for i in range(n)])\n    edges = []\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            p = p_in if labels[i] == labels[j] else p_out\n            if np.random.rand() < p:\n                if balanced:\n                    edges.append([i, j])  # Consistent: low -> high\n                else:\n                    # Random direction creates odd cycles\n                    if np.random.rand() < 0.5:\n                        edges.append([i, j])\n                    else:\n                        edges.append([j, i])\n    \n    if len(edges) == 0:\n        edges = [[0, 1]]\n    \n    return torch.tensor(edges, dtype=torch.long).t(), labels\n\n\n# Test generators\nprint(\"Testing graph generators...\")\nfor name, balanced in [(\"Balanced\", True), (\"Unbalanced\", False)]:\n    ei, lab = generate_sbm(50, 3, 0.3, 0.1, balanced)\n    score = unbalance_score(ei, 50)\n    print(f\"{name} SBM: {ei.shape[1]} edges, unbalance={score:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: GNN Models\n\nclass GCN(nn.Module):\n    \"\"\"Standard 2-layer Graph Convolutional Network.\"\"\"\n    \n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, out_dim)\n    \n    def forward(self, x, A):\n        # Layer 1: aggregate -> transform -> activate\n        x = A @ x\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.5, training=self.training)\n        \n        # Layer 2: aggregate -> transform\n        x = A @ x\n        x = self.fc2(x)\n        \n        return F.log_softmax(x, dim=1)\n\n\nclass MagNet(nn.Module):\n    \"\"\"\n    Magnetic Graph Neural Network.\n    \n    Uses complex adjacency to encode edge direction.\n    Processes real and imaginary channels separately then combines.\n    \"\"\"\n    \n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super().__init__()\n        # Separate transforms for real and imaginary parts\n        self.fc1_re = nn.Linear(in_dim, hidden_dim)\n        self.fc1_im = nn.Linear(in_dim, hidden_dim)\n        self.fc2_re = nn.Linear(hidden_dim, out_dim)\n        self.fc2_im = nn.Linear(hidden_dim, out_dim)\n    \n    def forward(self, x, A_mag):\n        # Layer 1: complex aggregation\n        x_c = x.to(torch.complex64)\n        h = A_mag @ x_c\n        \n        # Process real and imaginary separately, then combine\n        h_re = F.relu(self.fc1_re(h.real))\n        h_im = F.relu(self.fc1_im(h.imag))\n        h = h_re + h_im\n        h = F.dropout(h, p=0.5, training=self.training)\n        \n        # Layer 2: complex aggregation\n        h_c = h.to(torch.complex64)\n        h = A_mag @ h_c\n        \n        out = self.fc2_re(h.real) + self.fc2_im(h.imag)\n        \n        return F.log_softmax(out, dim=1)\n\n\nprint(\"Models defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Training & Evaluation\n\ndef train_eval(model, x, A, labels, train_mask, test_mask, epochs=200):\n    \"\"\"Train model and return test accuracy.\"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \n    model.train()\n    for _ in range(epochs):\n        optimizer.zero_grad()\n        out = model(x, A)\n        loss = F.nll_loss(out[train_mask], labels[train_mask])\n        loss.backward()\n        optimizer.step()\n    \n    model.eval()\n    with torch.no_grad():\n        pred = model(x, A).argmax(dim=1)\n        acc = (pred[test_mask] == labels[test_mask]).float().mean()\n    \n    return acc.item()\n\n\nprint(\"Training function ready!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Main Experiment\n\ndef run_experiment(num_trials=10, q=0.1):\n    \"\"\"Run full experiment comparing GCN vs MagNet.\"\"\"\n    results = []\n    n, k = 100, 4\n    \n    for name, balanced in [(\"Balanced\", True), (\"Unbalanced\", False)]:\n        print(f\"\\n{name}:\")\n        for trial in range(num_trials):\n            # Generate graph\n            edge_index, labels = generate_sbm(n, k, 0.3, 0.05, balanced)\n            A_gcn, A_mag = build_matrices(edge_index, n, q)\n            \n            # Features and masks\n            x = torch.randn(n, 16)\n            perm = torch.randperm(n)\n            train_mask = torch.zeros(n, dtype=torch.bool)\n            train_mask[perm[:60]] = True\n            test_mask = ~train_mask\n            \n            # Compute unbalance score\n            score = unbalance_score(edge_index, n, q)\n            \n            # Train GCN\n            gcn = GCN(16, 32, k)\n            acc_gcn = train_eval(gcn, x, A_gcn, labels, train_mask, test_mask)\n            \n            # Train MagNet\n            magnet = MagNet(16, 32, k)\n            acc_mag = train_eval(magnet, x, A_mag, labels, train_mask, test_mask)\n            \n            delta = acc_mag - acc_gcn\n            \n            results.append({\n                'config': name,\n                'trial': trial,\n                'unbalance': score,\n                'gcn': acc_gcn,\n                'magnet': acc_mag,\n                'delta': delta\n            })\n            \n            print(f\"  {trial}: unbal={score:.3f}, GCN={acc_gcn:.3f}, MagNet={acc_mag:.3f}, d={delta:+.3f}\")\n    \n    return pd.DataFrame(results)\n\n\n# Run experiment\nprint(\"Starting experiment...\")\ndf = run_experiment(num_trials=10, q=0.1)\nprint(\"\\nExperiment complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Visualization\n\n# Summary statistics\nprint(\"Summary by configuration:\")\nsummary = df.groupby('config')[['unbalance', 'gcn', 'magnet', 'delta']].mean()\nprint(summary.round(3))\nprint()\n\n# Plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Left: Scatter of unbalance vs delta\ncolors = {'Balanced': 'blue', 'Unbalanced': 'red'}\nfor cfg in df['config'].unique():\n    sub = df[df['config'] == cfg]\n    ax1.scatter(sub['unbalance'], sub['delta'], label=cfg,\n               c=colors[cfg], alpha=0.7, s=80)\nax1.axhline(0, color='k', linestyle='--', alpha=0.3)\nax1.set_xlabel('Unbalance Score')\nax1.set_ylabel('MagNet - GCN Accuracy')\nax1.set_title('Structural Unbalance vs Performance Gap')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Right: Bar comparison\nx_pos = np.arange(2)\nax2.bar(x_pos - 0.175, summary['gcn'], 0.35, label='GCN', color='steelblue')\nax2.bar(x_pos + 0.175, summary['magnet'], 0.35, label='MagNet', color='coral')\nax2.set_xticks(x_pos)\nax2.set_xticklabels(summary.index)\nax2.set_ylabel('Accuracy')\nax2.set_title('Model Comparison')\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('structural_balance_results.png', dpi=150)\nplt.show()\n\nprint(\"\\nFigure saved as 'structural_balance_results.png'\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8: Statistical Analysis\n\n# Correlation\ncorr, p_corr = stats.pearsonr(df['unbalance'], df['delta'])\nprint(f\"Correlation (unbalance vs delta): r={corr:.3f}, p={p_corr:.4f}\")\n\n# T-test between groups\nbal = df[df['config'] == 'Balanced']['delta']\nunbal = df[df['config'] == 'Unbalanced']['delta']\nt, p = stats.ttest_ind(unbal, bal)\nprint(f\"T-test: t={t:.3f}, p={p:.4f}\")\n\n# Conclusion\nprint(\"\\n\" + \"=\"*50)\nprint(\"CONCLUSION:\")\nif corr > 0.2 and unbal.mean() > bal.mean():\n    print(\"SUPPORTS hypothesis: MagNet advantage on unbalanced graphs\")\nelif corr < -0.2:\n    print(\"CONTRADICTS hypothesis\")\nelse:\n    print(\"INCONCLUSIVE - need more trials or different setup\")\nprint(\"=\"*50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Notes\n\n**Key parameters:**\n- `q=0.1`: Phase parameter for magnetic adjacency (good real/imag balance)\n- `n=100, k=4`: 100 nodes, 4 classes in SBM\n- `p_in=0.3, p_out=0.05`: Edge probabilities\n\n**If results are inconclusive:**\n- Try different `q` values (0.05, 0.15, 0.2)\n- Increase `num_trials`\n- Try larger graphs or different SBM parameters"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}